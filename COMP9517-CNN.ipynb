{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f58e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import random\n",
    "from utils.elpv_reader import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Activation,Conv2D, MaxPooling2D,GlobalMaxPooling2D,BatchNormalization\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score\n",
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed7a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "images, proba, types = load_dataset()\n",
    "# change label, label will be 0 1 2 3\n",
    "label_mapping = {0.0: 0, 0.3333333333333333: 1, 0.6666666666666666: 2, 1.0: 3}\n",
    "for x in range(len(proba)):\n",
    "    if proba[x] in label_mapping:\n",
    "        proba[x] = label_mapping[proba[x]]\n",
    "# get the infomations of images\n",
    "num_images, height, width = images.shape\n",
    "# Create a new numpy array to store the resized and denoised images\n",
    "resized_images = np.empty((num_images, 64, 64), dtype=np.uint8)\n",
    "# use for loop, resize every image and denoise it\n",
    "for i in range(num_images):\n",
    "    resized_images[i] = cv2.resize(images[i], (64,64))\n",
    "    resized_images[i] = cv2.GaussianBlur(resized_images[i], (3, 3),0)\n",
    "# split the dataset into train set and test set 75% for train , 25% for test\n",
    "X_train, X_test, y_train, y_test =  train_test_split(resized_images, proba,train_size=0.75,stratify=proba, random_state=30,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19218058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverSampling\n",
    "class_indices1 = np.where(y_train == 1)[0]\n",
    "samples_to_copy1= np.random.choice(class_indices1, size=100, replace=False)\n",
    "X_train = np.concatenate([X_train, X_train[samples_to_copy1]])\n",
    "y_train = np.concatenate([y_train, y_train[samples_to_copy1]])\n",
    "\n",
    "class_indices2 = np.where(y_train == 2)[0]\n",
    "samples_to_copy2 = np.random.choice(class_indices2, size=160, replace=True)\n",
    "X_train = np.concatenate([X_train, X_train[samples_to_copy2]])\n",
    "y_train = np.concatenate([y_train, y_train[samples_to_copy2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7ed83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Enhancement ------- purpose is make the perfomance better, for example, rotation/scaling can reduce the overfiiting and increase the data diversity\n",
    "# Contrast Enhancement \n",
    "new_X_train = X_train.copy()\n",
    "new_y_train = y_train.copy()\n",
    "for x in range(len(new_X_train)):\n",
    "   new_X_train[x] = cv2.equalizeHist(X_train[x])\n",
    "new_X_train = np.concatenate([X_train, new_X_train])\n",
    "new_y_train = np.concatenate([y_train, new_y_train])\n",
    "\n",
    "# flip(horiton + vertical)\n",
    "temp_X = X_train.copy()\n",
    "temp_y = y_train.copy()\n",
    "for i in range(len(temp_X)):\n",
    "    temp_X[i] = cv2.flip(X_train[i],1)\n",
    "new_X_train = np.concatenate([new_X_train, temp_X])\n",
    "new_y_train = np.concatenate([new_y_train, temp_y])\n",
    "\n",
    "#Some random rotation (-30 - 30 degrees)\n",
    "temp_X = X_train.copy()\n",
    "temp_y = y_train.copy()\n",
    "for i in range(len(temp_X)):\n",
    "    rows, cols = X_train[i].shape\n",
    "    random_angle = random.randint(-30, 30)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), random_angle, 1)\n",
    "    temp_X[i] = cv2.warpAffine(X_train[i], rotation_matrix, (cols, rows))\n",
    "new_X_train = np.concatenate([new_X_train, temp_X])\n",
    "new_y_train = np.concatenate([new_y_train, temp_y])\n",
    "# Fianlly, add some noise on the original image, now we get around 10K train set\n",
    "temp_X = X_train.copy()\n",
    "temp_y = y_train.copy()\n",
    "for i in range(len(temp_X)):\n",
    "    noise = np.random.normal(loc=0, scale=15, size=X_train[i].shape)\n",
    "    temp_X[i] = np.clip(X_train[i] + noise, 0, 255).astype(np.float32)\n",
    "new_X_train = np.concatenate([new_X_train, temp_X])\n",
    "new_y_train = np.concatenate([new_y_train, temp_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d2f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type to float 32\n",
    "new_X_train = new_X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "# add channel, make sure the image is 4D\n",
    "new_X_train = new_X_train.reshape(new_X_train.shape[0], new_X_train.shape[1], new_X_train.shape[2],1)\n",
    "# make sure all pixel is in [0,1]\n",
    "new_X_train = new_X_train / 255\n",
    "# find all mono images\n",
    "all_mono = []\n",
    "monocrystalline_indices = np.where(types == 'mono')[0]\n",
    "for i in range(len(X_test)):\n",
    "    for j in monocrystalline_indices:\n",
    "        if np.array_equal(X_test[i],resized_images[j]):\n",
    "            all_mono.append(i)\n",
    "# find all poly images\n",
    "all_poly = []\n",
    "polycrystalline_indices = np.where(types == 'poly')[0]\n",
    "for i in range(len(X_test)):\n",
    "    for j in polycrystalline_indices:\n",
    "        if np.array_equal(X_test[i],resized_images[j]):\n",
    "            all_poly.append(i)\n",
    "# make sure all pixel is in [0,1]   \n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc45db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 , Use CNN model (current parameters is not big_best_model,since we tried a lot different models)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu',input_shape=(64, 64, 1)))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "# big best model using 512/256, instead of 2048 2048\n",
    "model.add(Dense(2048,activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(2048,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629c5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the model built up, we can compile the model, using a low learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "             loss=SparseCategoricalFocalLoss(gamma=2),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771737ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 21.8628 - accuracy: 0.4688\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48148, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 80s 267ms/step - loss: 21.8628 - accuracy: 0.4688 - val_loss: 15.9333 - val_accuracy: 0.4815\n",
      "Epoch 2/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 11.6985 - accuracy: 0.5252\n",
      "Epoch 2: val_accuracy did not improve from 0.48148\n",
      "294/294 [==============================] - 72s 246ms/step - loss: 11.6985 - accuracy: 0.5252 - val_loss: 8.5126 - val_accuracy: 0.3648\n",
      "Epoch 3/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 6.2920 - accuracy: 0.5431\n",
      "Epoch 3: val_accuracy improved from 0.48148 to 0.50788, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 75s 255ms/step - loss: 6.2920 - accuracy: 0.5431 - val_loss: 4.6277 - val_accuracy: 0.5079\n",
      "Epoch 4/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.5330 - accuracy: 0.5583\n",
      "Epoch 4: val_accuracy did not improve from 0.50788\n",
      "294/294 [==============================] - 77s 263ms/step - loss: 3.5330 - accuracy: 0.5583 - val_loss: 2.7223 - val_accuracy: 0.4853\n",
      "Epoch 5/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.1097 - accuracy: 0.5741\n",
      "Epoch 5: val_accuracy improved from 0.50788 to 0.53895, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 83s 281ms/step - loss: 2.1097 - accuracy: 0.5741 - val_loss: 1.6814 - val_accuracy: 0.5390\n",
      "Epoch 6/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.3724 - accuracy: 0.5927\n",
      "Epoch 6: val_accuracy improved from 0.53895 to 0.58323, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 86s 291ms/step - loss: 1.3724 - accuracy: 0.5927 - val_loss: 1.1647 - val_accuracy: 0.5832\n",
      "Epoch 7/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.9901 - accuracy: 0.6052\n",
      "Epoch 7: val_accuracy improved from 0.58323 to 0.64283, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 78s 264ms/step - loss: 0.9901 - accuracy: 0.6052 - val_loss: 0.8555 - val_accuracy: 0.6428\n",
      "Epoch 8/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.6303\n",
      "Epoch 8: val_accuracy did not improve from 0.64283\n",
      "294/294 [==============================] - 76s 260ms/step - loss: 0.7736 - accuracy: 0.6303 - val_loss: 0.7289 - val_accuracy: 0.6386\n",
      "Epoch 9/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.6396\n",
      "Epoch 9: val_accuracy improved from 0.64283 to 0.65006, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 76s 260ms/step - loss: 0.6563 - accuracy: 0.6396 - val_loss: 0.6072 - val_accuracy: 0.6501\n",
      "Epoch 10/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.6628\n",
      "Epoch 10: val_accuracy did not improve from 0.65006\n",
      "294/294 [==============================] - 78s 264ms/step - loss: 0.5778 - accuracy: 0.6628 - val_loss: 0.6022 - val_accuracy: 0.6266\n",
      "Epoch 11/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.6671\n",
      "Epoch 11: val_accuracy did not improve from 0.65006\n",
      "294/294 [==============================] - 76s 259ms/step - loss: 0.5278 - accuracy: 0.6671 - val_loss: 0.6386 - val_accuracy: 0.6258\n",
      "Epoch 12/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.6932\n",
      "Epoch 12: val_accuracy improved from 0.65006 to 0.68370, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 73s 250ms/step - loss: 0.4852 - accuracy: 0.6932 - val_loss: 0.4998 - val_accuracy: 0.6837\n",
      "Epoch 13/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.7082\n",
      "Epoch 13: val_accuracy improved from 0.68370 to 0.72584, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 72s 246ms/step - loss: 0.4485 - accuracy: 0.7082 - val_loss: 0.4634 - val_accuracy: 0.7258\n",
      "Epoch 14/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.7271\n",
      "Epoch 14: val_accuracy improved from 0.72584 to 0.72712, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 73s 250ms/step - loss: 0.4145 - accuracy: 0.7271 - val_loss: 0.4264 - val_accuracy: 0.7271\n",
      "Epoch 15/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.7466\n",
      "Epoch 15: val_accuracy did not improve from 0.72712\n",
      "294/294 [==============================] - 72s 244ms/step - loss: 0.3841 - accuracy: 0.7466 - val_loss: 0.4788 - val_accuracy: 0.6645\n",
      "Epoch 16/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.7507\n",
      "Epoch 16: val_accuracy improved from 0.72712 to 0.76288, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 73s 247ms/step - loss: 0.3655 - accuracy: 0.7507 - val_loss: 0.3684 - val_accuracy: 0.7629\n",
      "Epoch 17/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.7755\n",
      "Epoch 17: val_accuracy did not improve from 0.76288\n",
      "294/294 [==============================] - 76s 258ms/step - loss: 0.3341 - accuracy: 0.7755 - val_loss: 0.4750 - val_accuracy: 0.7011\n",
      "Epoch 18/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.7908\n",
      "Epoch 18: val_accuracy improved from 0.76288 to 0.81524, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 75s 255ms/step - loss: 0.3066 - accuracy: 0.7908 - val_loss: 0.3145 - val_accuracy: 0.8152\n",
      "Epoch 19/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.8053\n",
      "Epoch 19: val_accuracy did not improve from 0.81524\n",
      "294/294 [==============================] - 75s 256ms/step - loss: 0.2919 - accuracy: 0.8053 - val_loss: 0.4993 - val_accuracy: 0.7250\n",
      "Epoch 20/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.8178\n",
      "Epoch 20: val_accuracy did not improve from 0.81524\n",
      "294/294 [==============================] - 76s 256ms/step - loss: 0.2736 - accuracy: 0.8178 - val_loss: 0.2937 - val_accuracy: 0.8093\n",
      "Epoch 21/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.8297\n",
      "Epoch 21: val_accuracy did not improve from 0.81524\n",
      "294/294 [==============================] - 77s 262ms/step - loss: 0.2566 - accuracy: 0.8297 - val_loss: 0.3185 - val_accuracy: 0.8067\n",
      "Epoch 22/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.8356\n",
      "Epoch 22: val_accuracy improved from 0.81524 to 0.84121, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 75s 256ms/step - loss: 0.2407 - accuracy: 0.8356 - val_loss: 0.2632 - val_accuracy: 0.8412\n",
      "Epoch 23/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.8489\n",
      "Epoch 23: val_accuracy improved from 0.84121 to 0.84930, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 75s 257ms/step - loss: 0.2314 - accuracy: 0.8489 - val_loss: 0.2352 - val_accuracy: 0.8493\n",
      "Epoch 24/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.8484\n",
      "Epoch 24: val_accuracy did not improve from 0.84930\n",
      "294/294 [==============================] - 73s 247ms/step - loss: 0.2243 - accuracy: 0.8484 - val_loss: 0.2634 - val_accuracy: 0.8250\n",
      "Epoch 25/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.8567\n",
      "Epoch 25: val_accuracy did not improve from 0.84930\n",
      "294/294 [==============================] - 79s 270ms/step - loss: 0.2158 - accuracy: 0.8567 - val_loss: 0.3407 - val_accuracy: 0.7969\n",
      "Epoch 26/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.8626\n",
      "Epoch 26: val_accuracy did not improve from 0.84930\n",
      "294/294 [==============================] - 75s 255ms/step - loss: 0.2026 - accuracy: 0.8626 - val_loss: 0.2640 - val_accuracy: 0.8318\n",
      "Epoch 27/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.8772\n",
      "Epoch 27: val_accuracy did not improve from 0.84930\n",
      "294/294 [==============================] - 72s 245ms/step - loss: 0.1869 - accuracy: 0.8772 - val_loss: 0.2950 - val_accuracy: 0.8135\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.8895\n",
      "Epoch 28: val_accuracy improved from 0.84930 to 0.85568, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 72s 246ms/step - loss: 0.1692 - accuracy: 0.8895 - val_loss: 0.2349 - val_accuracy: 0.8557\n",
      "Epoch 29/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.8828\n",
      "Epoch 29: val_accuracy improved from 0.85568 to 0.86547, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 72s 245ms/step - loss: 0.1798 - accuracy: 0.8828 - val_loss: 0.2100 - val_accuracy: 0.8655\n",
      "Epoch 30/30\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.8903\n",
      "Epoch 30: val_accuracy improved from 0.86547 to 0.86633, saving model to new_best_model.h5\n",
      "294/294 [==============================] - 73s 250ms/step - loss: 0.1693 - accuracy: 0.8903 - val_loss: 0.2086 - val_accuracy: 0.8663\n"
     ]
    }
   ],
   "source": [
    "# use checkpoint to save the model, we saved 'big_best_model' as our best result. In order to avoid overwriting, we used a new name \"new_best_model\"\n",
    "checkpoint = ModelCheckpoint('new_best_model.h5', \n",
    "                             monitor='val_accuracy',  \n",
    "                             save_best_only=True,  \n",
    "                             mode='max',  #\n",
    "                             verbose=1)  \n",
    "# fit the model, use 20% as validation set; store the values in [history], for the graph plot(the loss graph,used to check overfitting)\n",
    "history = model.fit(new_X_train,new_y_train,batch_size=32, epochs=30,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea42d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model (currently using the trained model,it can be changed to others)\n",
    "best_model = load_model('big_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d96b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 61ms/step\n",
      "Confusion Matrix for All Images:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75       377\n",
      "           1       0.44      0.47      0.46        74\n",
      "           2       0.04      0.04      0.04        26\n",
      "           3       0.68      0.57      0.62       179\n",
      "\n",
      "    accuracy                           0.66       656\n",
      "   macro avg       0.47      0.46      0.47       656\n",
      "weighted avg       0.66      0.66      0.65       656\n",
      "\n",
      "[[293  29  18  37]\n",
      " [ 31  35   3   5]\n",
      " [ 15   4   1   6]\n",
      " [ 63  11   3 102]]\n"
     ]
    }
   ],
   "source": [
    "# predict all images, and change the possibility to exactly class\n",
    "y_pred = best_model.predict(X_test)\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "y_test = y_test.astype(int)\n",
    "# evaluate, f1score / recall /predictions and confusion matrix\n",
    "f1_score = classification_report(y_test, predicted_labels)\n",
    "confusion  = confusion_matrix(y_test,predicted_labels)\n",
    "# print the results\n",
    "print(\"Confusion Matrix for All Images:\")\n",
    "print(f1_score)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "301fc21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (Accuracy): 77.72%\n",
      "Class 1 (Accuracy): 47.30%\n",
      "Class 2 (Accuracy): 3.85%\n",
      "Class 3 (Accuracy): 56.98%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for each class\n",
    "accuracy_class_0 = confusion[0, 0] / np.sum(confusion[0, :])\n",
    "accuracy_class_1 = confusion[1, 1] / np.sum(confusion[1, :])\n",
    "accuracy_class_2 = confusion[2, 2] / np.sum(confusion[2, :])\n",
    "accuracy_class_3 = confusion[3, 3] / np.sum(confusion[3, :])\n",
    "# Print the results with accuracy\n",
    "print(f\"Class 0 (Accuracy): {accuracy_class_0:.2%}\")\n",
    "print(f\"Class 1 (Accuracy): {accuracy_class_1:.2%}\")\n",
    "print(f\"Class 2 (Accuracy): {accuracy_class_2:.2%}\")\n",
    "print(f\"Class 3 (Accuracy): {accuracy_class_3:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "297022bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 62ms/step\n",
      "Confusion Matrix for Monocrystalline Images:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       151\n",
      "           1       0.54      0.59      0.56        37\n",
      "           2       0.09      0.08      0.08        13\n",
      "           3       0.70      0.63      0.67        71\n",
      "\n",
      "    accuracy                           0.67       272\n",
      "   macro avg       0.52      0.52      0.51       272\n",
      "weighted avg       0.67      0.67      0.67       272\n",
      "\n",
      "[[114  14   8  15]\n",
      " [ 12  22   1   2]\n",
      " [  7   3   1   2]\n",
      " [ 23   2   1  45]]\n"
     ]
    }
   ],
   "source": [
    "# Select only the monocrystalline image and calculate the confusion matrix\n",
    "y_pred_monocrystalline = best_model.predict(X_test[all_mono])\n",
    "predicted_labels_monocrystalline = np.argmax(y_pred_monocrystalline, axis=1)\n",
    "confusion_monocrystalline = confusion_matrix(y_test[all_mono], predicted_labels_monocrystalline)\n",
    "f1_score_monocrystalline = classification_report(y_test[all_mono], predicted_labels_monocrystalline)\n",
    "print(\"Confusion Matrix for Monocrystalline Images:\")\n",
    "print(f1_score_monocrystalline)\n",
    "print(confusion_monocrystalline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aeb933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monocrystalline Class 0 (Accuracy): 75.50%\n",
      "Monocrystalline Class 1 (Accuracy): 59.46%\n",
      "Monocrystalline Class 2 (Accuracy): 7.69%\n",
      "Monocrystalline Class 3 (Accuracy): 63.38%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for monocrystalline class\n",
    "accuracy_mono_class_0 = confusion_monocrystalline[0, 0] / np.sum(confusion_monocrystalline[0, :])\n",
    "accuracy_mono_class_1 = confusion_monocrystalline[1, 1] / np.sum(confusion_monocrystalline[1, :])\n",
    "accuracy_mono_class_2 = confusion_monocrystalline[2, 2] / np.sum(confusion_monocrystalline[2, :])\n",
    "accuracy_mono_class_3 = confusion_monocrystalline[3, 3] / np.sum(confusion_monocrystalline[3, :])\n",
    "# Print the results with accuracy for monocrystalline\n",
    "print(f\"Monocrystalline Class 0 (Accuracy): {accuracy_mono_class_0:.2%}\")\n",
    "print(f\"Monocrystalline Class 1 (Accuracy): {accuracy_mono_class_1:.2%}\")\n",
    "print(f\"Monocrystalline Class 2 (Accuracy): {accuracy_mono_class_2:.2%}\")\n",
    "print(f\"Monocrystalline Class 3 (Accuracy): {accuracy_mono_class_3:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b10d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 61ms/step\n",
      "Confusion Matrix for Polycrystalline Images:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76       226\n",
      "           1       0.34      0.35      0.35        37\n",
      "           2       0.00      0.00      0.00        13\n",
      "           3       0.66      0.53      0.59       108\n",
      "\n",
      "    accuracy                           0.65       384\n",
      "   macro avg       0.43      0.42      0.42       384\n",
      "weighted avg       0.65      0.65      0.65       384\n",
      "\n",
      "[[179  15  10  22]\n",
      " [ 19  13   2   3]\n",
      " [  8   1   0   4]\n",
      " [ 40   9   2  57]]\n"
     ]
    }
   ],
   "source": [
    "# Select only the polycrystalline images and calculate the confusion matrix\n",
    "y_pred_polycrystalline = best_model.predict(X_test[all_poly])\n",
    "predicted_labels_polycrystalline = np.argmax(y_pred_polycrystalline, axis=1)\n",
    "confusion_polycrystalline = confusion_matrix(y_test[all_poly], predicted_labels_polycrystalline)\n",
    "f1_score_polycrystalline = classification_report(y_test[all_poly], predicted_labels_polycrystalline)\n",
    "print(\"Confusion Matrix for Polycrystalline Images:\")\n",
    "print(f1_score_polycrystalline)\n",
    "print(confusion_polycrystalline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1079b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polycrystalline Class 0 (Accuracy): 79.20%\n",
      "Polycrystalline Class 1 (Accuracy): 35.14%\n",
      "Polycrystalline Class 2 (Accuracy): 0.00%\n",
      "Polycrystalline Class 3 (Accuracy): 52.78%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for polycrystalline class\n",
    "accuracy_poly_class_0 = confusion_polycrystalline[0, 0] / np.sum(confusion_polycrystalline[0, :])\n",
    "accuracy_poly_class_1 = confusion_polycrystalline[1, 1] / np.sum(confusion_polycrystalline[1, :])\n",
    "accuracy_poly_class_2 = confusion_polycrystalline[2, 2] / np.sum(confusion_polycrystalline[2, :])\n",
    "accuracy_poly_class_3 = confusion_polycrystalline[3, 3] / np.sum(confusion_polycrystalline[3, :])\n",
    "\n",
    "# Print the results with accuracy for polycrystalline\n",
    "print(f\"Polycrystalline Class 0 (Accuracy): {accuracy_poly_class_0:.2%}\")\n",
    "print(f\"Polycrystalline Class 1 (Accuracy): {accuracy_poly_class_1:.2%}\")\n",
    "print(f\"Polycrystalline Class 2 (Accuracy): {accuracy_poly_class_2:.2%}\")\n",
    "print(f\"Polycrystalline Class 3 (Accuracy): {accuracy_poly_class_3:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
