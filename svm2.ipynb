{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T04:33:04.982827Z",
     "start_time": "2023-11-08T04:33:04.971654Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.elpv_reader import load_dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2624, 300, 300)\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "['mono' 'mono' 'mono' ... 'poly' 'poly' 'poly']\n",
      "Best number of PCA components for 'mono': 21\n",
      "Best cross-validation accuracy for 'mono': 0.6857142857142857\n",
      "Best number of PCA components for 'poly': 9\n",
      "Best cross-validation accuracy for 'poly': 0.6600377386414088\n",
      "Classification report for 'mono' images:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 120\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# Print the classification reports for the test sets of \"mono\" and \"poly\" images\u001B[39;00m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification report for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmono\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m images:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28mprint\u001B[39m(metrics\u001B[38;5;241m.\u001B[39mclassification_report(y_mono_test\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m), predict_labels_mono))\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification report for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoly\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m images:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28mprint\u001B[39m(metrics\u001B[38;5;241m.\u001B[39mclassification_report(y_poly_test\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m), predict_labels_poly))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# Load the dataset and print some information\n",
    "images, proba, types = load_dataset()\n",
    "print(images.shape)\n",
    "print(proba)\n",
    "print(types)\n",
    "\n",
    "# Step 1: Classify images into \"mono\" and \"poly\" based on \"types\"\n",
    "# You can create two separate lists for \"mono\" and \"poly\" images\n",
    "mono_images = []\n",
    "poly_images = []\n",
    "poly_proba=[]\n",
    "mono_proba=[]\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    if types[i] == \"mono\":\n",
    "        mono_images.append(images[i])\n",
    "        mono_proba.append((proba[i]))\n",
    "    elif types[i] == \"poly\":\n",
    "        poly_images.append(images[i])\n",
    "        poly_proba.append((proba[i]))\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "mono_images = np.array(mono_images)\n",
    "poly_images = np.array(poly_images)\n",
    "\n",
    "# Step 2: Split the dataset into train and test sets for both \"mono\" and \"poly\" images\n",
    "# Adjust the test_size and random_state as needed\n",
    "x_mono_train, x_mono_test, y_mono_train, y_mono_test = train_test_split(mono_images, mono_proba, test_size=0.25, random_state=42)\n",
    "x_poly_train, x_poly_test, y_poly_train, y_poly_test = train_test_split(poly_images, poly_proba, test_size=0.25, random_state=42)\n",
    "\n",
    "y_mono_train =np.array(y_mono_train)\n",
    "y_poly_train=np.array(y_poly_train)\n",
    "\n",
    "\n",
    "# Step 3: Convert each image to pixel histograms (histograms can be shared)\n",
    "his_train_mono = []\n",
    "his_test_mono = []\n",
    "his_train_poly = []\n",
    "his_test_poly = []\n",
    "\n",
    "for image in x_mono_train:\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0.0, 255.0])\n",
    "    his_train_mono.append(((hist / 255).flatten()))\n",
    "\n",
    "for image in x_mono_test:\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0.0, 255.0])\n",
    "    his_test_mono.append(((hist / 255).flatten()))\n",
    "\n",
    "for image in x_poly_train:\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0.0, 255.0])\n",
    "    his_train_poly.append(((hist / 255).flatten()))\n",
    "\n",
    "for image in x_poly_test:\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0.0, 255.0])\n",
    "    his_test_poly.append(((hist / 255).flatten()))\n",
    "\n",
    "# Step 4: Preprocess, train, and evaluate SVM models separately for \"mono\" and \"poly\" images\n",
    "his_train_mono = np.array(his_train_mono)\n",
    "his_test_mono = np.array(his_test_mono)\n",
    "\n",
    "his_train_poly = np.array(his_train_poly)\n",
    "his_test_poly = np.array(his_test_poly)\n",
    "\n",
    "# Create MinMaxScaler objects separately for \"mono\" and \"poly\" images\n",
    "scaler_mono = MinMaxScaler()\n",
    "scaler_poly = MinMaxScaler()\n",
    "\n",
    "# Fit the scalers to the training data and transform it\n",
    "his_train_normalized_mono = scaler_mono.fit_transform(his_train_mono)\n",
    "his_test_normalized_mono = scaler_mono.transform(his_test_mono)\n",
    "\n",
    "his_train_normalized_poly = scaler_poly.fit_transform(his_train_poly)\n",
    "his_test_normalized_poly = scaler_poly.transform(his_test_poly)\n",
    "\n",
    "# Create separate PCA and SVM models for \"mono\" and \"poly\" images\n",
    "pipeline_mono = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('svm', SVC(kernel=\"linear\"))\n",
    "])\n",
    "\n",
    "pipeline_poly = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('svm', SVC(kernel=\"linear\"))\n",
    "])\n",
    "\n",
    "# Define a range of PCA components to try (can adjust separately)\n",
    "param_grid = {\n",
    "    'pca__n_components': range(1, his_train_normalized_mono.shape[1] + 1)\n",
    "}\n",
    "\n",
    "# Create GridSearchCV objects separately for \"mono\" and \"poly\" images\n",
    "grid_search_mono = GridSearchCV(pipeline_mono, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_poly = GridSearchCV(pipeline_poly, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid searches to the normalized training data\n",
    "grid_search_mono.fit(his_train_normalized_mono, y_mono_train.astype(\"str\"))\n",
    "grid_search_poly.fit(his_train_normalized_poly, y_poly_train.astype(\"str\"))\n",
    "\n",
    "# Get the best number of PCA components and the best scores separately for \"mono\" and \"poly\" images\n",
    "best_n_components_mono = grid_search_mono.best_estimator_.named_steps['pca'].n_components\n",
    "best_score_mono = grid_search_mono.best_score_\n",
    "print(f\"Best number of PCA components for 'mono': {best_n_components_mono}\")\n",
    "print(f\"Best cross-validation accuracy for 'mono': {best_score_mono}\")\n",
    "\n",
    "best_n_components_poly = grid_search_poly.best_estimator_.named_steps['pca'].n_components\n",
    "best_score_poly = grid_search_poly.best_score_\n",
    "print(f\"Best number of PCA components for 'poly': {best_n_components_poly}\")\n",
    "print(f\"Best cross-validation accuracy for 'poly': {best_score_poly}\")\n",
    "\n",
    "# Use the best models found by the grid searches to make predictions on the test sets\n",
    "best_model_mono = grid_search_mono.best_estimator_\n",
    "predict_labels_mono = best_model_mono.predict(his_test_normalized_mono)\n",
    "\n",
    "best_model_poly = grid_search_poly.best_estimator_\n",
    "predict_labels_poly = best_model_poly.predict(his_test_normalized_poly)\n",
    "\n",
    "# Print the classification reports for the test sets of \"mono\" and \"poly\" images\n",
    "print(\"Classification report for 'mono' images:\")\n",
    "print(metrics.classification_report(y_mono_test.astype(\"str\"), predict_labels_mono))\n",
    "\n",
    "print(\"Classification report for 'poly' images:\")\n",
    "print(metrics.classification_report(y_poly_test.astype(\"str\"), predict_labels_poly))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T04:40:41.364330Z",
     "start_time": "2023-11-08T04:33:04.994838Z"
    }
   },
   "id": "d19ca7ce9be2a7be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
